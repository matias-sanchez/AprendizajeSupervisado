{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the given labels\n",
    "breed = pd.read_csv('../data/breed_labels.csv')\n",
    "color = pd.read_csv('../data/color_labels.csv')\n",
    "state = pd.read_csv('../data/state_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at the labels, just to understand what these are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BreedID</th>\n",
       "      <th>Type</th>\n",
       "      <th>BreedName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Afghan Hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Airedale Terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Akbash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Akita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BreedID  Type         BreedName\n",
       "0        1     1     Affenpinscher\n",
       "1        2     1      Afghan Hound\n",
       "2        3     1  Airedale Terrier\n",
       "3        4     1            Akbash\n",
       "4        5     1             Akita"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColorID</th>\n",
       "      <th>ColorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Golden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ColorID ColorName\n",
       "0        1     Black\n",
       "1        2     Brown\n",
       "2        3    Golden\n",
       "3        4    Yellow\n",
       "4        5     Cream"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateID</th>\n",
       "      <th>StateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41336</td>\n",
       "      <td>Johor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41325</td>\n",
       "      <td>Kedah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41367</td>\n",
       "      <td>Kelantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41401</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41415</td>\n",
       "      <td>Labuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41324</td>\n",
       "      <td>Melaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41332</td>\n",
       "      <td>Negeri Sembilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41335</td>\n",
       "      <td>Pahang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41330</td>\n",
       "      <td>Perak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41380</td>\n",
       "      <td>Perlis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41327</td>\n",
       "      <td>Pulau Pinang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41345</td>\n",
       "      <td>Sabah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41342</td>\n",
       "      <td>Sarawak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41326</td>\n",
       "      <td>Selangor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41361</td>\n",
       "      <td>Terengganu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StateID        StateName\n",
       "0     41336            Johor\n",
       "1     41325            Kedah\n",
       "2     41367         Kelantan\n",
       "3     41401     Kuala Lumpur\n",
       "4     41415           Labuan\n",
       "5     41324           Melaka\n",
       "6     41332  Negeri Sembilan\n",
       "7     41335           Pahang\n",
       "8     41330            Perak\n",
       "9     41380           Perlis\n",
       "10    41327     Pulau Pinang\n",
       "11    41345            Sabah\n",
       "12    41342          Sarawak\n",
       "13    41326         Selangor\n",
       "14    41361       Terengganu"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are ready to deal with the *original* dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'Description',\n",
       "       'AdoptionSpeed', 'PID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.454734</td>\n",
       "      <td>10.520412</td>\n",
       "      <td>265.469854</td>\n",
       "      <td>74.388868</td>\n",
       "      <td>1.779059</td>\n",
       "      <td>2.230675</td>\n",
       "      <td>3.236912</td>\n",
       "      <td>1.856738</td>\n",
       "      <td>1.860518</td>\n",
       "      <td>1.460971</td>\n",
       "      <td>1.729730</td>\n",
       "      <td>1.566528</td>\n",
       "      <td>1.912115</td>\n",
       "      <td>1.036666</td>\n",
       "      <td>1.584011</td>\n",
       "      <td>20.809960</td>\n",
       "      <td>41345.994613</td>\n",
       "      <td>2.518900</td>\n",
       "      <td>7477.025799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497970</td>\n",
       "      <td>18.374027</td>\n",
       "      <td>60.121490</td>\n",
       "      <td>123.434010</td>\n",
       "      <td>0.684763</td>\n",
       "      <td>1.743985</td>\n",
       "      <td>2.748595</td>\n",
       "      <td>2.974465</td>\n",
       "      <td>0.547535</td>\n",
       "      <td>0.593843</td>\n",
       "      <td>0.670791</td>\n",
       "      <td>0.701482</td>\n",
       "      <td>0.564041</td>\n",
       "      <td>0.198228</td>\n",
       "      <td>1.488348</td>\n",
       "      <td>78.397243</td>\n",
       "      <td>32.409109</td>\n",
       "      <td>1.176018</td>\n",
       "      <td>4310.921553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41324.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41326.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3768.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41326.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7473.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41401.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11200.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>41415.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14992.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type           Age        Breed1        Breed2        Gender  \\\n",
       "count  10582.000000  10582.000000  10582.000000  10582.000000  10582.000000   \n",
       "mean       1.454734     10.520412    265.469854     74.388868      1.779059   \n",
       "std        0.497970     18.374027     60.121490    123.434010      0.684763   \n",
       "min        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        1.000000      2.000000    265.000000      0.000000      1.000000   \n",
       "50%        1.000000      3.000000    266.000000      0.000000      2.000000   \n",
       "75%        2.000000     12.000000    307.000000    188.000000      2.000000   \n",
       "max        2.000000    255.000000    307.000000    307.000000      3.000000   \n",
       "\n",
       "             Color1        Color2        Color3  MaturitySize     FurLength  \\\n",
       "count  10582.000000  10582.000000  10582.000000  10582.000000  10582.000000   \n",
       "mean       2.230675      3.236912      1.856738      1.860518      1.460971   \n",
       "std        1.743985      2.748595      2.974465      0.547535      0.593843   \n",
       "min        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%        1.000000      0.000000      0.000000      2.000000      1.000000   \n",
       "50%        2.000000      2.000000      0.000000      2.000000      1.000000   \n",
       "75%        3.000000      6.000000      5.000000      2.000000      2.000000   \n",
       "max        7.000000      7.000000      7.000000      4.000000      3.000000   \n",
       "\n",
       "         Vaccinated      Dewormed    Sterilized        Health      Quantity  \\\n",
       "count  10582.000000  10582.000000  10582.000000  10582.000000  10582.000000   \n",
       "mean       1.729730      1.566528      1.912115      1.036666      1.584011   \n",
       "std        0.670791      0.701482      0.564041      0.198228      1.488348   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000      2.000000      1.000000      1.000000   \n",
       "50%        2.000000      1.000000      2.000000      1.000000      1.000000   \n",
       "75%        2.000000      2.000000      2.000000      1.000000      1.000000   \n",
       "max        3.000000      3.000000      3.000000      3.000000     20.000000   \n",
       "\n",
       "                Fee         State  AdoptionSpeed           PID  \n",
       "count  10582.000000  10582.000000   10582.000000  10582.000000  \n",
       "mean      20.809960  41345.994613       2.518900   7477.025799  \n",
       "std       78.397243     32.409109       1.176018   4310.921553  \n",
       "min        0.000000  41324.000000       0.000000      0.000000  \n",
       "25%        0.000000  41326.000000       2.000000   3768.250000  \n",
       "50%        0.000000  41326.000000       2.000000   7473.500000  \n",
       "75%        0.000000  41401.000000       4.000000  11200.750000  \n",
       "max     3000.000000  41415.000000       4.000000  14992.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>This is a stray kitten that came to my house. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>41326</td>\n",
       "      <td>anyone within the area of ipoh or taiping who ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n",
       "0     2    3     299       0       1       1       7       0             1   \n",
       "1     1    4     307       0       2       1       2       0             2   \n",
       "2     1    1     307       0       1       1       0       0             2   \n",
       "3     2    3     266       0       2       5       6       0             2   \n",
       "4     2   12     264     264       1       1       0       0             2   \n",
       "\n",
       "   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n",
       "0          1           2         2           2       1         1  100  41326   \n",
       "1          1           1         1           2       1         1  150  41401   \n",
       "2          1           2         2           2       1         1    0  41326   \n",
       "3          1           2         2           2       1         1    0  41326   \n",
       "4          3           2         2           3       1         1  300  41326   \n",
       "\n",
       "                                         Description  AdoptionSpeed  PID  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...              2    0  \n",
       "1  Good guard dog, very alert, active, obedience ...              2    3  \n",
       "2  This handsome yet cute boy is up for adoption....              2    4  \n",
       "3  This is a stray kitten that came to my house. ...              2    5  \n",
       "4  anyone within the area of ipoh or taiping who ...              1    6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to transform the datasets. This is done by means of a function so that the transformations are the same for the training and testing datasets... We replace the encodings just to make it easy to \"visualize\" the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    def transform_columns(df):\n",
    "        df = df.drop([\"Description\"], axis=1)\n",
    "        df.Type = df.Type.replace({1: 'Dog', 2: 'Cat'})\n",
    "        df.Gender = df.Gender.replace({1:'Male', 2:'Female', 3:'Mixed'})\n",
    "        df.MaturitySize = df.MaturitySize.replace({1:'S', 2:'M', 3:'L', 4:'XL', 0:'N/A'})\n",
    "        df.FurLength = df.FurLength.replace({1:'S', 2:'M', 3:'L', 0:'N/A'})\n",
    "        df.Vaccinated = df.Vaccinated.replace({1:'T', 2:'N', 3:'N/A'})\n",
    "        df.Dewormed = df.Dewormed.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Sterilized = df.Sterilized.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Health = df.Health.replace({1:'Healthy', 2: 'MinorInjury', 3:'SeriousInjury', 0: 'N/A'})\n",
    "        df.Color1 = df.Color1.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color2 = df.Color2.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color3 = df.Color3.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Breed1 = df.Breed1.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        df.Breed2 = df.Breed2.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        return df\n",
    "    \n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train = transform_columns(df_train)\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test = transform_columns(df_test)\n",
    "    \n",
    "    df = pd.concat([df_train, df_test], sort=True)\n",
    "\n",
    "    # set dummy variables for everything\n",
    "    # except from Age, Quantity, Fee\n",
    "    df = pd.get_dummies(df)\n",
    "    # get train and test back\n",
    "    n = len(df_train)\n",
    "    df_train = df.iloc[:n]\n",
    "    df_test = df.iloc[n:]\n",
    "    \n",
    "    y = df_train['AdoptionSpeed']\n",
    "    X = df_train.drop('AdoptionSpeed', axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop('AdoptionSpeed', axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.3519622095560508\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it couldn be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "tree_param = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(1, 2, 5),\n",
    "              'min_samples_split':(2, 3, 5, 10, 50, 100)}\n",
    "tree = DT(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, scoring='accuracy', cv=3, iid=False)\n",
    "tree_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_\n",
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally**, we predict the unknown label for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10582, 360), (4411, 360))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we do is generating a file that should be *submitted* on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission_tree.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SGDClassifier accuracy:  0.27881212583567705\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='adaptive', loss='hinge',\n",
      "       max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='adaptive', loss='hinge',\n",
      "       max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "param_grid = [{'loss': ['hinge', 'log', 'perceptron'], 'learning_rate': ['constant','optimal','invscaling','adaptive'],\\\n",
    "            'eta0': [0.1, 0.01, 0.001],  'alpha': [0.1, 0.01, 0.001]}]\n",
    "clf = SGDClassifier(random_state=42,tol=1e-3)\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring='accuracy', cv=5, iid=False,n_jobs=4,verbose = 5)\n",
    "grid_search.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_sgd_clf = grid_search.best_estimator_\n",
    "print('Best SGDClassifier accuracy: ', grid_search.best_score_)\n",
    "print(best_sgd_clf)\n",
    "results = results.append({'clf': best_sgd_clf, 'best_acc': grid_search.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission_sgd.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:  3.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC accuracy:  0.3191625641658338\n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "The best classifier so far is: \n",
      "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "param_grid = [{'C': [0.001, 0.01, 0.1, 1, 10], 'loss': ['hinge', 'squared_hinge'] }]\n",
    "linear_svc = LinearSVC(max_iter=10000)\n",
    "grid_search = GridSearchCV(linear_svc, param_grid, scoring='accuracy', cv=3, iid=False,n_jobs=4,verbose = 5)\n",
    "grid_search.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_lin_clf = grid_search.best_estimator_\n",
    "print('Best LinearSVC accuracy: ', grid_search.best_score_)\n",
    "print(best_lin_clf)\n",
    "results = results.append({'clf': best_lin_clf, 'best_acc': grid_search.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission_svc.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3600 candidates, totalling 10800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=4)]: Done 1144 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 1450 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=4)]: Done 2170 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=4)]: Done 2584 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=4)]: Done 3034 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=4)]: Done 3520 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=4)]: Done 4600 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=4)]: Done 5194 tasks      | elapsed: 54.2min\n",
      "[Parallel(n_jobs=4)]: Done 5824 tasks      | elapsed: 63.3min\n",
      "[Parallel(n_jobs=4)]: Done 6490 tasks      | elapsed: 68.1min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=4)]: Done 7930 tasks      | elapsed: 91.0min\n",
      "[Parallel(n_jobs=4)]: Done 8704 tasks      | elapsed: 102.2min\n",
      "[Parallel(n_jobs=4)]: Done 9514 tasks      | elapsed: 109.2min\n",
      "[Parallel(n_jobs=4)]: Done 10360 tasks      | elapsed: 120.5min\n",
      "[Parallel(n_jobs=4)]: Done 10800 out of 10800 | elapsed: 137.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest accuracy:  0.37964088024841364\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "The best classifier so far is: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "param_grid = [{'n_estimators': [100,200,300,400,500,600,700,800,900,1000], \\\n",
    "               'max_depth': [1,2,3,4,5,6,7,8,9,None], 'min_samples_split': [2,3,4,5,6,7,8,9,10], \\\n",
    "               'bootstrap': [True, False],'criterion': [\"gini\", \"entropy\"]}]\n",
    "grid_search = GridSearchCV(rnd_clf, param_grid, cv=3, scoring='accuracy',n_jobs=4,verbose = 5)\n",
    "grid_search.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_rnd_clf = grid_search.best_estimator_\n",
    "print('Best RandomForest accuracy: ', grid_search.best_score_)\n",
    "print(best_rnd_clf)\n",
    "results = results.append({'clf': best_rnd_clf, 'best_acc': grid_search.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission_rnd.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed:    1.5s remaining:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed:    2.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MultiLayer Perceptron accuracy:  0.2770352369380316\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "The best classifier so far is: \n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "param_grid = [{'hidden_layer_sizes': [(10,),(5,5), (2,2)]}]\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, cv=3, scoring='accuracy', return_train_score=True, n_jobs=4,verbose = 5)\n",
    "grid_search.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_mlp_clf = grid_search.best_estimator_\n",
    "print('Best MultiLayer Perceptron accuracy: ', grid_search.best_score_)\n",
    "print(best_mlp_clf)\n",
    "results = results.append({'clf': best_mlp_clf, 'best_acc': grid_search.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission_mlp.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed:    1.6s remaining:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed:    2.4s remaining:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoostClassifier accuracy:  0.36978533819360065\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=42)\n",
      "The best classifier so far is: \n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=100, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "param_grid = [{'n_estimators': [50, 100, 500]}]\n",
    "grid_search = GridSearchCV(ada_clf, param_grid, cv=3, scoring='accuracy', return_train_score=True, n_jobs=4,verbose = 5)\n",
    "grid_search.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_ada_clf = grid_search.best_estimator_\n",
    "print('Best AdaBoostClassifier accuracy: ', grid_search.best_score_)\n",
    "print(best_ada_clf)\n",
    "results = results.append({'clf': best_ada_clf, 'best_acc': grid_search.best_score_}, ignore_index=True)\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission_ada.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=[('tre', best_tree_clf), ('sgd', best_sgd_clf), \\\n",
    "                                          ('lin', best_lin_clf), ('rnd', best_rnd_clf), \\\n",
    "                                          ('mlp', best_mlp_clf), ('ada', best_ada_clf)],voting='hard')\n",
    "voting_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "yy = voting_clf.predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission_vote.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 359 and input n_features is 360 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e903a999f2b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoting_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 'hard' voting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             maj = np.apply_along_axis(\n\u001b[0;32m    236\u001b[0m                 lambda x: np.argmax(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \"\"\"\n\u001b[0;32m    415\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 359 and input n_features is 360 "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = voting_clf.predict(X_train)\n",
    "accuracy_score(y_train, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0710 04:26:48.629817  6304 deprecation_wrapper.py:119] From C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0710 04:26:48.647821  6304 deprecation_wrapper.py:119] From C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0710 04:26:48.650806  6304 deprecation_wrapper.py:119] From C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0710 04:26:48.679796  6304 deprecation_wrapper.py:119] From C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0710 04:26:48.694795  6304 deprecation_wrapper.py:119] From C:\\Users\\Matías\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (2,) but got array with shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-034a2ef15484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (2,) but got array with shape (5,)"
     ]
    }
   ],
   "source": [
    "#! pip install tensorflow\n",
    "#! pip install keras\n",
    "from keras.layers import Dense \n",
    "from keras.models import Sequential \n",
    "from keras.utils import to_categorical \n",
    "\n",
    "predictors = X.as_matrix() \n",
    "target = to_categorical(y)\n",
    "n_cols = predictors.shape[1] \n",
    "model = Sequential() \n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "model.fit(predictors, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
